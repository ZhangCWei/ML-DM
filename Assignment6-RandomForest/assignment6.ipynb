{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc9ef1a",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验六:随机森林</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef6f7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c19637",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:函数介绍</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302e25c",
   "metadata": {},
   "source": [
    "介绍一些可能会用到的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ba5e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 4 4 1 2 2 4 2 2]\n",
      "[[ 9 10 11]\n",
      " [ 0  1  2]\n",
      " [12 13 14]\n",
      " [ 6  7  8]\n",
      " [ 3  4  5]]\n",
      "   0  1  2\n",
      "2  2  2  2\n",
      "4  4  4  4\n",
      "   0  1  2\n",
      "1  1  1  1\n",
      "2  2  2  2\n"
     ]
    }
   ],
   "source": [
    "# np.random.choice函数从一个一维数组中随机采样\n",
    "x = np.array([1,2,3,4])\n",
    "y = np.random.choice(x, replace=True, size=10)\n",
    "print(y)\n",
    "\n",
    "# np.random.shuffle函数对一个数组/矩阵按照第一维进行洗牌\n",
    "x = np.array([[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14]])\n",
    "np.random.shuffle(x)\n",
    "print(x)\n",
    "\n",
    "# DataFrame对象的sample函数可以随机采样n个数据或者采样比例为frac的数据\n",
    "x = np.array([[0,0,0],[1,1,1],[2,2,2],[3,3,3],[4,4,4]])\n",
    "frame = pd.DataFrame(x)\n",
    "print(frame.sample(n=2))\n",
    "print(frame.sample(frac=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca268aef",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验任务</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365ec76",
   "metadata": {},
   "source": [
    "本次实验承接上次实验，实现随机森林。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96a745",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">本次实验依旧使用泰坦尼克号数据集(train_titanic.csv, test_titanic.csv。数据集包括了四个属性特征以及一个标签(即为Survived,代表是否生还),属性特征分别为Sex(性别)，sibsp(堂兄弟妹个数)，Parch(父母与小孩的个数)，Pclass(乘客等级)  \n",
    "其中该数据集无缺失值和异常值，且所有连续变量已自动转换为离散变量,标签(Survived)也自动转变为离散变量0和1，所以你无需进行数据预处理，可以直接使用该数据集。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967202a",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 对上次实验的best_split函数进行修改，实现随机特征选择。  \n",
    "先从特征集$A$中先随机选取$k$个特征构成特征集$A'$，再从$A'$中选取最佳划分的特征。$k$一般取$max\\{log_2 d,1\\}$, $d$是$A$的元素的个数。你可使用特征的信息增益来决定最佳划分的特征。  \n",
    "    【输入】：数据集D、特征集A    \n",
    "    【输出】：随机特征集A'中最佳划分的特征维数   \n",
    "    【信息增益公式】:  \n",
    "        某数据集D有若干特征值以及对应的标签值，其总样本大小为|D|,这里取其中一个特征feature,该特征包含V个不同的取值，特征值为第v(v=1,2,...,V)个值的数量为|$D^v$|$(\\sum_{v=1}^VD^v=|D|)$,则该特征对应的信息增益为$$Gain(D,feature)=Ent(D)-\\sum_{v=1}^K \\frac{|D^v|}{D} Ent(D^v)$$  \n",
    "    【信息熵公式】:  \n",
    "        某数组包含K个不同的取值，样本为第k(k=1,2,...,K)个值的数量所占比例为p_k,则其信息熵为$$Ent=-\\sum_{k=1}^K p_k log_2 p_k$$\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b55657f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算标签数组的信息熵\n",
    "def entropy(label):\n",
    "    unique_classes, counts = np.unique(label, return_counts=True)\n",
    "    total_samples = len(label)\n",
    "    entropy_value = 0\n",
    "    \n",
    "    for count in counts:\n",
    "        p_k = count / total_samples\n",
    "        entropy_value -= p_k * np.log2(p_k)\n",
    "\n",
    "    return entropy_value\n",
    "\n",
    "# 计算考虑属性信息后的条件熵、给定维度的条件下的信息熵\n",
    "def conditional_entropy(x_data, y_label, dimension):\n",
    "    \n",
    "    # 获取某个特征的所有可能取值\n",
    "    unique_values = np.unique(x_data[:, dimension])\n",
    "    total_samples = len(y_label)\n",
    "    cond_entropy_value = 0\n",
    "\n",
    "    for value in unique_values:\n",
    "        # 获取相应特征的标签值\n",
    "        sub_indices = np.where(x_data[:, dimension] == value)[0]\n",
    "        sub_labels = y_label[sub_indices]\n",
    "        \n",
    "        # 计算占比\n",
    "        sub_samples = len(sub_labels)\n",
    "        p = sub_samples / total_samples\n",
    "        \n",
    "        # 计算条件熵\n",
    "        sub_entropy = entropy(sub_labels)\n",
    "        cond_entropy_value += p * sub_entropy\n",
    "\n",
    "    return cond_entropy_value\n",
    "\n",
    "# 选择信息增益最大的特征输出\n",
    "def one_split_ID3(x_data, y_label):\n",
    "    num_features = x_data.shape[1]\n",
    "    total_entropy = entropy(y_label)\n",
    "    best_info_gain = 0\n",
    "    best_dimension = None\n",
    "\n",
    "    for dimension in range(num_features):\n",
    "        cond_entropy = conditional_entropy(x_data, y_label, dimension)\n",
    "        info_gain = total_entropy - cond_entropy\n",
    "\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_dimension = dimension\n",
    "        \n",
    "    return best_info_gain, best_dimension\n",
    "\n",
    "\n",
    "def best_split(D, A):\n",
    "    \n",
    "    best_info_gain = 0\n",
    "    best_dimension = None\n",
    "\n",
    "    k = max(int(np.log2(len(A))), 1)\n",
    "    A_new = random.sample(list(A), k)\n",
    "\n",
    "    for dimension in A_new:\n",
    "        x_data = D[:, dimension].reshape(-1, 1)\n",
    "        info_gain, _ = one_split_ID3(x_data, D[:, -1])\n",
    "        \n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_dimension = dimension\n",
    "    \n",
    "    return best_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa003e",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 对上次实验完成的决策树类进行修改。你需要实现下面三个函数：  \n",
    "1. TreeGenerate(self, D, A)：递归构建决策树，伪代码参照提供的“Algorithm 1 决策树学习基本算法”。  \n",
    "2. train(self, D)：做一些数据预处理，包括将Dataframe转换为numpy矩阵，从数据集中提取属性集，并调用TreeGenerate函数来递归地生成决策树。  \n",
    "3. predict(self, D)：对测试集D进行预测，要求返回数据集D的预测标签，即一个(|D|,1)矩阵（|D|行1列）。  \n",
    "由于训练集是采样生成，因此需要对predict函数做修改。需要考虑测试集中出现决策树无法划分的特征值时的情况。给出两种参考的做法：  \n",
    "a).对其不再进行预测，直接给定划分失败的样本标签(例如-1)。  \n",
    "b).跳过该划分节点，随机选取一个特征值继续遍历。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a275ce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记下所有属性可能的取值\n",
    "train_frame = pd.read_csv('train_titanic.csv')\n",
    "D = np.array(train_frame)\n",
    "A = set(range(D.shape[1] - 1))\n",
    "possible_value = {}\n",
    "for every in A:\n",
    "    possible_value[every] = np.unique(D[:, every])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d03dbc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 树结点类\n",
    "class Node:\n",
    "    def __init__(self, isLeaf=True, label=-1, index=-1):\n",
    "        self.isLeaf = isLeaf # isLeaf表示该结点是否是叶结点\n",
    "        self.label = label # label表示该叶结点的label（当结点为叶结点时有用）\n",
    "        self.index = index # index表示该分支结点的划分属性的序号（当结点为分支结点时有用）\n",
    "        self.children = {} # children表示该结点的所有孩子结点，dict类型，方便进行决策树的搜索\n",
    "        \n",
    "    def addNode(self, val, node):\n",
    "        self.children[val] = node #为当前结点增加一个划分属性的值为val的孩子结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12e76c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树类\n",
    "class DTree:\n",
    "    def __init__(self):\n",
    "        self.tree_root = None #决策树的根结点\n",
    "        self.possible_value = possible_value # 用于存储每个属性可能的取值\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    TreeGenerate函数用于递归构建决策树,伪代码参照课件中的“Algorithm 1 决策树学习基本算法”\n",
    "    '''\n",
    "    def TreeGenerate(self, D, A):\n",
    "        \n",
    "        node = Node(isLeaf=False)\n",
    "\n",
    "        # if D中样本全属于同一类别C then\n",
    "        if len(np.unique(D[:, -1])) == 1:\n",
    "            node.isLeaf = True\n",
    "            node.label = D[0, -1]  # 叶结点的类别为D中唯一的类别,取第一行最后一列\n",
    "            return node\n",
    "        # end if\n",
    "\n",
    "        # if A = Ø OR D中样本在A上取值相同 then\n",
    "        if len(A) == 0 or len(np.unique(D[:, list(A)])) == 1:\n",
    "            node.isLeaf = True\n",
    "            node.label = np.argmax(np.bincount(D[:, -1]))  # 叶结点的类别为D中样本最多的类\n",
    "            return node\n",
    "        # end if\n",
    "\n",
    "        # 从A中选择最优划分特征a_star\n",
    "        a_star = best_split(D, A)\n",
    "        if a_star is None:\n",
    "            node.isLeaf = True\n",
    "            node.label = np.argmax(np.bincount(D[:, -1]))  # 叶结点的类别为D中样本最多的类\n",
    "            return node\n",
    "\n",
    "        node.index = a_star  # 设置分支节点的划分特征\n",
    "\n",
    "        # for a_star 的每一个值a_star_v do\n",
    "        for a_star_v in self.possible_value[a_star]:\n",
    "            # D_v是D在a_star上取值为a_star_v的样本子集\n",
    "            D_v = D[D[:, a_star] == a_star_v]\n",
    "            \n",
    "            if len(D_v) == 0:\n",
    "                child_node = Node(isLeaf=True, label=np.argmax(np.bincount(D[:, -1])))\n",
    "            else:\n",
    "                A_new = A - {a_star}\n",
    "                child_node = self.TreeGenerate(D_v, A_new)\n",
    "\n",
    "            node.addNode(a_star_v, child_node)\n",
    "        # end for\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    train函数可以做一些数据预处理(比如Dataframe到numpy矩阵的转换,提取属性集等),并调用TreeGenerate函数来递归地生成决策树\n",
    "    '''\n",
    "    def train(self, D):\n",
    "        # 将Dataframe对象转换为numpy矩阵（也可以不转，自行决定做法）\n",
    "        D = np.array(D) \n",
    "        \n",
    "        # 特征集A\n",
    "        A = set(range(D.shape[1] - 1))\n",
    "        \n",
    "        #记下每个特征可能的取值\n",
    "        for every in A:\n",
    "            self.possible_value[every] = np.unique(D[:, every])\n",
    "\n",
    "        # 递归地生成决策树，并将决策树的根结点赋值给self.tree_root\n",
    "        self.tree_root = self.TreeGenerate(D, A)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    predict函数对测试集D进行预测,输出预测标签\n",
    "    '''\n",
    "    def predict(self, D):\n",
    "        # 将测试集 D 转化为 NumPy 数组\n",
    "        D = np.array(D)\n",
    "        # 用于存储预测的标签\n",
    "        predictions = []\n",
    "\n",
    "        # 对测试集中的每个样本进行预测\n",
    "        for i in range(len(D)):\n",
    "            # 从根节点开始遍历决策树\n",
    "            current_node = self.tree_root\n",
    "\n",
    "            # 循环遍历树，直到达到叶节点为止\n",
    "            while not current_node.isLeaf:\n",
    "                # 获取当前节点的划分特征的索引\n",
    "                feature_index = current_node.index\n",
    "                # 获取当前样本在划分特征上的取值\n",
    "                feature_value = D[i, feature_index]\n",
    "\n",
    "                if feature_value in current_node.children:\n",
    "                    # 如果样本的特征值在当前节点的孩子节点中，继续向下遍历\n",
    "                    current_node = current_node.children[feature_value]\n",
    "                else:\n",
    "                    # 如果样本的特征值不在当前节点的孩子节点中,采取随机选择一个特征值继续遍历的策略\n",
    "                    available_features = list(current_node.children.keys())\n",
    "                    random_feature_value = np.random.choice(available_features)\n",
    "                    current_node = current_node.children[random_feature_value]\n",
    "\n",
    "            # 到达叶节点后，预测标签即为叶节点的类别\n",
    "            predicted_label = current_node.label\n",
    "            # 将预测标签添加到预测结果中\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        # 返回预测结果，将其转化为 NumPy 数组并重塑形状\n",
    "        return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff8753",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 重复采用Bootstrap自助采样法对训练数据集'train_titanic.csv'进行采样，生成$n$个子训练数据集($n$自行设定)。  \n",
    "Bootstrap采样法是指，每次从原数据集中【有放回】地随机采样一个样本，重复进行$m$次，就生成一个有$m$个样本的子数据集。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b674f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_frame = pd.read_csv('train_titanic.csv')\n",
    "\n",
    "# 生成n个子训练数据集\n",
    "n = 5\n",
    "\n",
    "# 存储生成的子训练数据集的列表\n",
    "sub_train_data_sets = []\n",
    "\n",
    "# 使用自助采样法生成子训练数据集\n",
    "for i in range(n):\n",
    "    # 随机有放回地抽取与原始数据集相同大小的样本\n",
    "    bootstrap_sample = train_frame.sample(frac=1, replace=True)\n",
    "    sub_train_data_sets.append(bootstrap_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd780da",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 生成n棵决策树实例，使用上述生成的n个子训练数据集各自训练一棵决策树，即子训练集D1训练决策树1，子训练集D2训练决策树2……</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13d5c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Your code here -------\n",
    "\n",
    "# 创建n棵决策树的列表\n",
    "decision_trees = []\n",
    "\n",
    "# 循环训练n棵决策树\n",
    "for i in range(n):\n",
    "    # 创建一个新的决策树实例\n",
    "    decision_tree = DTree()\n",
    "    \n",
    "    # 获取第i个子训练数据集\n",
    "    sub_train_data = sub_train_data_sets[i]\n",
    "    \n",
    "    # 训练决策树\n",
    "    decision_tree.train(sub_train_data)\n",
    "    \n",
    "    # 将训练好的决策树添加到列表中\n",
    "    decision_trees.append(decision_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7837970",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">5) 用训练完成的$n$棵决策树分别对测试数据集'test_titanic.csv'进行预测。采用相对多数投票法来对各棵决策树的预测结果进行结合。输出结合的预测结果的准确率。  \n",
    "【相对多数投票法】  \n",
    "对于某个样本$x$, 相对多数投票法预测它的标签为得票最多的标签。若同时有多个标签获得最高票，则从中随机选取一个。其公式如下所示：\n",
    "$$H(x)=C_{\\mathop{\\arg\\max}_{j} \\sum_{i=1}^n h_i^j(x)}$$  \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9896a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.8415841584158416\n"
     ]
    }
   ],
   "source": [
    "# 读取测试数据集\n",
    "test_frame = pd.read_csv('test_titanic.csv')\n",
    "\n",
    "# 用训练好的决策树进行预测\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(test_frame)):\n",
    "    # 统计每个决策树的预测结果\n",
    "    votes = {}\n",
    "    for j in range(n):\n",
    "        decision_tree = decision_trees[j]\n",
    "        prediction = decision_tree.predict(test_frame.iloc[i:i+1, :])\n",
    "        label = prediction[0, 0]\n",
    "        if label in votes:\n",
    "            votes[label] += 1\n",
    "        else:\n",
    "            votes[label] = 1\n",
    "    \n",
    "    # 找到得票最多的标签\n",
    "    max_votes = max(votes.values())\n",
    "    winning_labels = [label for label, vote_count in votes.items() if vote_count == max_votes]\n",
    "    \n",
    "    # 从得票最多的标签中随机选取一个作为预测结果\n",
    "    final_prediction = random.choice(winning_labels)\n",
    "    \n",
    "    predictions.append(final_prediction)\n",
    "\n",
    "# 计算准确率\n",
    "correct_labels = test_frame['Survived'].values\n",
    "predicted_labels = np.array(predictions)\n",
    "\n",
    "accuracy = np.mean(correct_labels == predicted_labels)\n",
    "print(\"准确率：\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       158\n",
      "           1       0.72      0.41      0.52        44\n",
      "\n",
      "    accuracy                           0.84       202\n",
      "   macro avg       0.79      0.68      0.71       202\n",
      "weighted avg       0.82      0.84      0.82       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用python内置库进行验证，结果基本一致\n",
    "from sklearn.ensemble import  RandomForestClassifier  # 随机森林分类器\n",
    "from sklearn.metrics import classification_report  # 生产报告\n",
    "\n",
    "# 假设最后一列是标签列，将其分离出来\n",
    "y_train = train_frame.iloc[:, -1]\n",
    "y_test = test_frame.iloc[:, -1]\n",
    "\n",
    "# 从DataFrame中去除最后一列以获得属性\n",
    "x_train = train_frame.iloc[:, :-1]\n",
    "x_test = test_frame.iloc[:, :-1]\n",
    "\n",
    "# 3.训练分类器\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "train_history = rfc.fit(x_train, y_train)\n",
    "\n",
    "# 4.测试\n",
    "pred = rfc.predict(x_test)\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "print(report)\n",
    "\n",
    "\"\"\"\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.96      0.90       158\n",
    "           1       0.72      0.41      0.52        44\n",
    "\n",
    "    accuracy                           0.84       202\n",
    "   macro avg       0.79      0.68      0.71       202\n",
    "weighted avg       0.82      0.84      0.82       202\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f62e5",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第三部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615aba6d",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)不要提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a43fe8",
   "metadata": {},
   "source": [
    "二、实验报告提交截止日期为：【10月27日 14:20】  \n",
    "提交地址：https://send2me.cn/g_kfMtFI/SuiqyPO6B7rxqg  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名-实验六.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26699b34",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址: https://www.jianguoyun.com/p/DTGgCYAQp5WhChir26EFIAA  \n",
    "实验内容获取地址: https://www.jianguoyun.com/p/DekWAFoQp5WhChis26EFIAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
